{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf1ec81-32c3-4502-9003-584102e4e383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:01:01.047836Z",
     "iopub.status.busy": "2024-12-16T21:01:01.047508Z",
     "iopub.status.idle": "2024-12-16T21:01:01.673439Z",
     "shell.execute_reply": "2024-12-16T21:01:01.670260Z",
     "shell.execute_reply.started": "2024-12-16T21:01:01.047799Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": [{\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"api_key\": os.environ[\"API_KEY\"]\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb250d9-7b58-414f-9d49-24e56ac9e628",
   "metadata": {},
   "source": [
    "#### Agent-triggered Termination\n",
    "\n",
    "_max_consecutive_auto_reply_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74a79fc-6030-4f7e-a075-3cc00c0a5cc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:05:27.874140Z",
     "iopub.status.busy": "2024-12-16T21:05:27.873775Z",
     "iopub.status.idle": "2024-12-16T21:05:27.983062Z",
     "shell.execute_reply": "2024-12-16T21:05:27.982171Z",
     "shell.execute_reply.started": "2024-12-16T21:05:27.874088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Classic, Cathy! That joke is always harvest-ing laughs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Cathy: Haha, nice one, Joe! With puns like that, we're bound to sow the seeds of laughter everywhere we go!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llm_config.update({\"temperature\":0.9})\n",
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo  of comedians.\",\n",
    "    llm_config = llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "llm_config.update({\"temperature\":0.7})\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo  of comedians.\",\n",
    "    llm_config = llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=1, # limit the number of consecutive auto replies\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f1347-bac4-42df-8a0e-44a18b5b5d8e",
   "metadata": {},
   "source": [
    "_is_termination_msg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "419179bf-31af-498e-95a2-d3626aa6a7aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:07:10.846791Z",
     "iopub.status.busy": "2024-12-16T21:07:10.846015Z",
     "iopub.status.idle": "2024-12-16T21:07:13.252919Z",
     "shell.execute_reply": "2024-12-16T21:07:13.251887Z",
     "shell.execute_reply.started": "2024-12-16T21:07:10.846754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke and then say the words GOOD BYE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, here's a joke for you:\n",
      "\n",
      "Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "GOOD BYE!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llm_config.update({\"temperature\":0.7})\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo  of comedians.\",\n",
    "    llm_config = llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"good bye\" in msg[\"content\"].lower(),\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke and then say the words GOOD BYE.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
